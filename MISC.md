# Tips and Tricks
From our experience of working with this repository, here are a few practical tips and tools that can be useful for evaluators.
- To prevent that an experiment is aborted due to a disconnection between your machine and the master instance, we recommend using the [screen](https://linux.die.net/man/1/screen) command on the master instance before running the actual benchmark command.
- The [screen](https://linux.die.net/man/1/screen) command is also useful for step 10 in the Setup Guide. We can SSH into the server instances, create a screen session and do ``./build.sc`` and then detach the session while it's building. In this way, we can build the multiple server instances in parallel.
- As described under "Parameters and Output" in the [README](./README.md), the log files are useful for monitoring the status of the benchmarks. In our experiments, the ``kompact_mixed.out`` should log at least once every 10 minutes. If there is no logging for a longer period, one should suspect that something has failed. However, usually the `./bench.sc` command will finish if there is a failure.
- If a benchmark fails (which can occur simply due to unstable connections at the cloud provider), one might need to rerun some experiments. Before that, we suggest ensuring that the processes was properly terminated at all server instances by running ``killall -r komp`` on each instance.
- If a failure occurs and we want to run a subset of the remaining experiments, we suggest editing the [Benchmarks.scala](./runner/src/main/scala/se/kth/benchmarks/runner/Benchmarks.scala) and setting to the desired benchmark space [here](https://github.com/haraldng/omnipaxos-artifacts/blob/main/runner/src/main/scala/se/kth/benchmarks/runner/Benchmarks.scala#L173). Don't forget to build afterwards.